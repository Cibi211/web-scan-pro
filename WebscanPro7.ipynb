{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733f62fa-a4b4-4325-91e8-65544f0e541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful (if credentials valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crawling:   0%|                                                                                 | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Crawled: http://localhost:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crawling:   7%|████▊                                                                    | 1/15 [00:01<00:14,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Testing Weak Credentials at http://localhost:8080/login.php\n",
      "[-] admin:admin rejected\n",
      "[-] admin:password rejected\n",
      "[-] root:root rejected\n",
      "[-] test:test rejected\n",
      "\n",
      "🔎 Checking Cookie Flags\n",
      "⚠️ Cookie flag issues: Missing HttpOnly, Missing Secure, Missing SameSite\n",
      "\n",
      "🔎 Testing IDOR at http://localhost:8080/vulnerabilities/idor/ (param=id)\n",
      "[?] id=1 returned content (needs review)\n",
      "[?] id=2 returned content (needs review)\n",
      "[?] id=3 returned content (needs review)\n",
      "[?] id=4 returned content (needs review)\n",
      "[?] id=5 returned content (needs review)\n",
      "\n",
      "🔎 Testing Access Control (Role Bypass)\n",
      "[-] http://localhost:8080/admin/ seems protected\n",
      "[-] http://localhost:8080/config.php seems protected\n",
      "🔥 Access Control issue → http://localhost:8080/vulnerabilities/ accessible without login\n",
      "\n",
      "=== Vulnerability Findings ===\n",
      "[Cookie-Issues]\n",
      "   Parameter: -\n",
      "   Issues: ['Missing HttpOnly', 'Missing Secure', 'Missing SameSite']\n",
      "   Evidence: Missing HttpOnly, Missing Secure, Missing SameSite\n",
      "--------------------------------------------------\n",
      "[Access-Control]\n",
      "   URL: http://localhost:8080/vulnerabilities/\n",
      "   Parameter: -\n",
      "   Evidence: Accessible without auth (HTTP 200)\n",
      "--------------------------------------------------\n",
      "\n",
      "📄 HTML report generated: reports\\webscan_report_localhost_8080.html\n",
      "\n",
      "=== Mitigation Tips ===\n",
      "SQLi Fixes: Use parameterized queries (PreparedStatements), ORM, input validation.\n",
      "XSS Fixes: Validate input, encode output, apply Content Security Policy (CSP).\n",
      "Auth/Access Control: Enforce strong passwords, rate limit login attempts, set cookie flags (HttpOnly, Secure, SameSite), and apply proper authorization checks.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "webscanpro.py\n",
    "Merged DVWA crawler + SQLi + XSS + Auth + AccessControl tester + HTML reporting (Jinja2).\n",
    "Generates: reports/webscan_report_<slugified-target>.html\n",
    "CSV export removed; report ensures 'parameter' and 'evidence' are filled when possible.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urljoin, urldefrag, urlparse, parse_qs, urlencode, urlunparse\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "\n",
    "# ==============================\n",
    "# Templates / Reporting\n",
    "# ==============================\n",
    "REPORT_TEMPLATE = \"\"\"\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\" />\n",
    "  <title>WebScanPro Report - {{ target }}</title>\n",
    "  <style>\n",
    "    body { font-family: Arial, sans-serif; padding: 20px; }\n",
    "    table { border-collapse: collapse; width: 100%; }\n",
    "    th, td { border: 1px solid #ddd; padding: 8px; }\n",
    "    th { background: #f4f4f4; }\n",
    "    .High { color: #a94442; font-weight: bold; }\n",
    "    .Medium { color: #8a6d3b; }\n",
    "    .Low { color: #3c763d; }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>WebScanPro Report</h1>\n",
    "  <p><strong>Target:</strong> {{ target }}</p>\n",
    "  <p><strong>Date:</strong> {{ date }}</p>\n",
    "\n",
    "  <h2>Findings ({{ findings|length }})</h2>\n",
    "  {% if findings %}\n",
    "  <table>\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th>Type</th>\n",
    "        <th>Endpoint / URL</th>\n",
    "        <th>Parameter / Field</th>\n",
    "        <th>Payload / Value</th>\n",
    "        <th>Evidence / Error / Issues</th>\n",
    "        <th>Severity</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      {% for f in findings %}\n",
    "      <tr>\n",
    "        <td>{{ f.type }}</td>\n",
    "        <td>{{ f.endpoint }}</td>\n",
    "        <td>{{ f.param }}</td>\n",
    "        <td>{{ f.payload }}</td>\n",
    "        <td>{{ f.evidence }}</td>\n",
    "        <td class=\"{{ f.severity }}\">{{ f.severity }}</td>\n",
    "      </tr>\n",
    "      {% endfor %}\n",
    "    </tbody>\n",
    "  </table>\n",
    "  {% else %}\n",
    "    <p>No findings.</p>\n",
    "  {% endif %}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def severity_from_type(t):\n",
    "    t = str(t or \"\")\n",
    "    if 'SQLi' in t or 'XSS' in t:\n",
    "        return 'High'\n",
    "    if 'IDOR' in t or 'Session' in t or 'credentials' in t.lower() or 'Weak-Credentials' in t:\n",
    "        return 'Medium'\n",
    "    return 'Low'\n",
    "\n",
    "\n",
    "class Reporter:\n",
    "    def __init__(self, target, findings, out_dir='reports'):\n",
    "        self.target = target\n",
    "        self.findings = findings or []\n",
    "        self.out_dir = out_dir\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    def _slugify(self, s):\n",
    "        s = re.sub(r'^\\w+://', '', s)  # remove scheme\n",
    "        s = s.strip().lower()\n",
    "        s = re.sub(r'[^a-z0-9]+', '_', s)\n",
    "        s = s.strip('_')\n",
    "        return s or 'target'\n",
    "\n",
    "    def normalize_findings(self):\n",
    "        \"\"\"Ensure template-friendly keys, map aliases and compute severity.\n",
    "        Prioritize populating param and evidence from available fields.\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for f in self.findings:\n",
    "            nf = dict(f)  # shallow copy\n",
    "\n",
    "            # alias mapping\n",
    "            if 'parameter' in nf and 'param' not in nf:\n",
    "                nf['param'] = nf.get('parameter')\n",
    "            if 'field' in nf and 'param' not in nf:\n",
    "                nf['param'] = nf.get('field')\n",
    "            if 'url' in nf and 'endpoint' not in nf:\n",
    "                nf['endpoint'] = nf.get('url')\n",
    "            if 'status' in nf and 'endpoint' not in nf:\n",
    "                nf['endpoint'] = str(nf.get('status'))\n",
    "\n",
    "            # defaults and payload/evidence selection\n",
    "            nf['type'] = nf.get('type', 'N/A')\n",
    "            nf['endpoint'] = nf.get('endpoint', nf.get('url', '-')) or '-'\n",
    "\n",
    "            # Parameter: try many fields to fill it\n",
    "            param_val = nf.get('param') or nf.get('parameter') or nf.get('field') or nf.get('value') or nf.get('username') or nf.get('param')\n",
    "            nf['param'] = param_val if param_val not in (None, '') else '-'\n",
    "\n",
    "            # Payload: prefer explicit payload or tested_value or username/password/value\n",
    "            nf['payload'] = nf.get('payload') or nf.get('tested_value') or nf.get('username') or nf.get('password') or nf.get('value') or '-'\n",
    "\n",
    "            # Evidence: prefer explicit evidence > error > issues > payload\n",
    "            evidence = nf.get('evidence')\n",
    "            if not evidence:\n",
    "                if 'error' in nf and nf.get('error'):\n",
    "                    evidence = nf.get('error')\n",
    "                elif 'issues' in nf and nf.get('issues'):\n",
    "                    issues = nf.get('issues')\n",
    "                    evidence = ', '.join(issues) if isinstance(issues, (list, tuple)) else str(issues)\n",
    "                elif nf.get('payload') and nf.get('payload') != '-':\n",
    "                    evidence = f\"Reflected/payload: {nf.get('payload')}\"\n",
    "                else:\n",
    "                    # small informative fallback\n",
    "                    evidence = nf.get('note') or '-'\n",
    "            nf['evidence'] = evidence or '-'\n",
    "\n",
    "            nf['severity'] = severity_from_type(nf['type'])\n",
    "            out.append(nf)\n",
    "        return out\n",
    "\n",
    "    def render_html(self):\n",
    "        findings = self.normalize_findings()\n",
    "        env = Environment(loader=FileSystemLoader('.'), autoescape=select_autoescape(['html','xml']))\n",
    "        template = env.from_string(REPORT_TEMPLATE)\n",
    "        content = template.render(\n",
    "            target=self.target,\n",
    "            date=datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S UTC\"),\n",
    "            findings=findings\n",
    "        )\n",
    "        slug = self._slugify(self.target)\n",
    "        out_path = os.path.join(self.out_dir, f\"webscan_report_{slug}.html\")\n",
    "        with open(out_path, 'w', encoding='utf-8') as fh:\n",
    "            fh.write(content)\n",
    "        return out_path\n",
    "\n",
    "# ==============================\n",
    "# Payloads & helpers\n",
    "# ==============================\n",
    "SQL_PAYLOADS = [\n",
    "    \"' OR '1'='1\",\n",
    "    '\" OR \"1\"=\"1',\n",
    "    \"1'--\",\n",
    "    \"1 OR 1=1\",\n",
    "    \"' UNION SELECT NULL--\"\n",
    "]\n",
    "\n",
    "SQL_ERROR_PATTERNS = [\n",
    "    \"you have an error in your sql syntax;\",\n",
    "    \"warning: mysql\",\n",
    "    \"unclosed quotation mark after the character string\",\n",
    "    \"quoted string not properly terminated\",\n",
    "    \"pg_query\",\n",
    "    \"mysql_fetch\",\n",
    "    \"sql error\"\n",
    "]\n",
    "\n",
    "def find_sql_errors(html):\n",
    "    for pattern in SQL_ERROR_PATTERNS:\n",
    "        if pattern.lower() in (html or \"\").lower():\n",
    "            return True, pattern\n",
    "    return False, None\n",
    "\n",
    "XSS_PAYLOADS = [\n",
    "    \"<script>alert(1)</script>\",\n",
    "    \"<img src=x onerror=alert(1)>\",\n",
    "    \"<svg onload=alert(1)>\"\n",
    "]\n",
    "REFLECT_PATTERNS = [re.compile(re.escape(p), re.IGNORECASE) for p in XSS_PAYLOADS]\n",
    "\n",
    "# ==============================\n",
    "# DVWA Web Crawler\n",
    "# ==============================\n",
    "class DVWACrawler:\n",
    "    def __init__(self, base_url, session=None, username=\"admin\", password=\"password\",\n",
    "                 max_pages=20, delay=2):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.max_pages = max_pages\n",
    "        self.delay = delay\n",
    "        self.session = session or requests.Session()\n",
    "        self.visited = set()\n",
    "        self.queue = deque([self.base_url])\n",
    "        self.pages = {}\n",
    "        self.forms = {}\n",
    "\n",
    "        # login (best-effort)\n",
    "        try:\n",
    "            self.login(username, password)\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Login failed or skipped: {e}\")\n",
    "\n",
    "    def normalize_url(self, url):\n",
    "        clean_url = url or \"\"\n",
    "        clean_url = urldefrag(clean_url)[0].rstrip(\"/\")\n",
    "        return clean_url\n",
    "\n",
    "    def login(self, username, password):\n",
    "        login_url = f\"{self.base_url}/login.php\"\n",
    "        resp = self.session.get(login_url, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        token = soup.find(\"input\", {\"name\": \"user_token\"})\n",
    "        token_val = token[\"value\"] if token else \"\"\n",
    "\n",
    "        payload = {\n",
    "            \"username\": username,\n",
    "            \"password\": password,\n",
    "            \"Login\": \"Login\",\n",
    "            \"user_token\": token_val\n",
    "        }\n",
    "\n",
    "        login_resp = self.session.post(login_url, data=payload, timeout=10)\n",
    "        if \"Login failed\" in login_resp.text:\n",
    "            raise Exception(\"Login failed: check credentials or CSRF token.\")\n",
    "        print(\"✅ Login successful (if credentials valid)\")\n",
    "\n",
    "    def extract_links(self, html, page_url):\n",
    "        soup = BeautifulSoup(html or \"\", \"html.parser\")\n",
    "        links = []\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            abs_url = urljoin(page_url, a[\"href\"])\n",
    "            clean_url = self.normalize_url(abs_url)\n",
    "            if clean_url.startswith(self.base_url):\n",
    "                links.append(clean_url)\n",
    "        return links\n",
    "\n",
    "    def extract_forms(self, html, page_url):\n",
    "        soup = BeautifulSoup(html or \"\", \"html.parser\")\n",
    "        forms = []\n",
    "        for form in soup.find_all(\"form\"):\n",
    "            details = {\n",
    "                \"method\": form.get(\"method\", \"get\").lower(),\n",
    "                \"action\": urljoin(page_url, form.get(\"action\", \"\")),\n",
    "                \"inputs\": []\n",
    "            }\n",
    "            for inp in form.find_all([\"input\", \"textarea\", \"select\"]):\n",
    "                details[\"inputs\"].append({\n",
    "                    \"name\": inp.get(\"name\"),\n",
    "                    \"type\": inp.get(\"type\", inp.name),\n",
    "                    \"value\": inp.get(\"value\", \"\")\n",
    "                })\n",
    "            forms.append(details)\n",
    "        return forms\n",
    "\n",
    "    def crawl(self):\n",
    "        with tqdm(total=self.max_pages, desc=\"Crawling\") as pbar:\n",
    "            while self.queue and len(self.visited) < self.max_pages:\n",
    "                url = self.normalize_url(self.queue.popleft())\n",
    "\n",
    "                if url in self.visited:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    resp = self.session.get(url, timeout=10)\n",
    "                    resp.raise_for_status()\n",
    "                    html = resp.text\n",
    "                except Exception as e:\n",
    "                    print(f\" Error fetching {url}: {e}\")\n",
    "                    self.visited.add(url)\n",
    "                    continue\n",
    "\n",
    "                self.pages[url] = html\n",
    "                page_forms = self.extract_forms(html, url)\n",
    "                if page_forms:\n",
    "                    self.forms[url] = page_forms\n",
    "\n",
    "                for link in self.extract_links(html, url):\n",
    "                    if link not in self.visited and link not in self.queue:\n",
    "                        self.queue.append(link)\n",
    "\n",
    "                self.visited.add(url)\n",
    "                print(f\"✅ Crawled: {url}\")\n",
    "                pbar.update(1)\n",
    "                time.sleep(self.delay)\n",
    "\n",
    "        return {\"pages\": self.pages, \"forms\": self.forms, \"session\": self.session}\n",
    "\n",
    "# ==============================\n",
    "# SQL Injection Scanner\n",
    "# ==============================\n",
    "class SQLiScanner:\n",
    "    def __init__(self, session, timeout=10):\n",
    "        self.session = session\n",
    "        self.timeout = timeout\n",
    "        self.findings = []\n",
    "\n",
    "    def test_url_params(self, url):\n",
    "        parsed = urlparse(url)\n",
    "        params = parse_qs(parsed.query)\n",
    "        if not params:\n",
    "            return\n",
    "        for param in params:\n",
    "            for payload in SQL_PAYLOADS:\n",
    "                test_params = params.copy()\n",
    "                test_params[param] = payload\n",
    "                new_query = urlencode(test_params, doseq=True)\n",
    "                new_url = urlunparse(parsed._replace(query=new_query))\n",
    "                try:\n",
    "                    resp = self.session.get(new_url, timeout=self.timeout)\n",
    "                    found, pattern = find_sql_errors(resp.text)\n",
    "                    if found:\n",
    "                        self.findings.append({\n",
    "                            \"type\": \"SQLi-URL\",\n",
    "                            \"url\": new_url,\n",
    "                            \"parameter\": param,\n",
    "                            \"payload\": payload,\n",
    "                            \"error\": pattern,\n",
    "                            \"evidence\": f\"SQL error matched: {pattern}\"\n",
    "                        })\n",
    "                        print(f\"🔥 SQLi detected in {new_url} param={param} payload={payload}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "                time.sleep(0.2)\n",
    "\n",
    "    def test_forms(self, forms_by_url):\n",
    "        for page_url, forms in forms_by_url.items():\n",
    "            for form in forms:\n",
    "                action = form.get(\"action\") or page_url\n",
    "                method = form.get(\"method\", \"get\").lower()\n",
    "                base_data = {inp[\"name\"]: (inp.get(\"value\") or \"test\")\n",
    "                             for inp in form[\"inputs\"] if inp.get(\"name\")}\n",
    "                for field in base_data:\n",
    "                    for payload in SQL_PAYLOADS:\n",
    "                        test_data = base_data.copy()\n",
    "                        test_data[field] = payload\n",
    "                        try:\n",
    "                            if method == \"post\":\n",
    "                                resp = self.session.post(action, data=test_data,\n",
    "                                                         timeout=self.timeout)\n",
    "                            else:\n",
    "                                resp = self.session.get(action, params=test_data,\n",
    "                                                        timeout=self.timeout)\n",
    "                            found, pattern = find_sql_errors(resp.text)\n",
    "                            if found:\n",
    "                                self.findings.append({\n",
    "                                    \"type\": \"SQLi-FORM\",\n",
    "                                    \"url\": action,\n",
    "                                    \"field\": field,\n",
    "                                    \"parameter\": field,\n",
    "                                    \"payload\": payload,\n",
    "                                    \"error\": pattern,\n",
    "                                    \"evidence\": f\"SQL error matched: {pattern}\"\n",
    "                                })\n",
    "                                print(f\"🔥 SQLi detected in form {action} field={field} payload={payload}\")\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        time.sleep(0.2)\n",
    "\n",
    "    def run(self, pages, forms):\n",
    "        for url in pages.keys():\n",
    "            self.test_url_params(url)\n",
    "        self.test_forms(forms)\n",
    "        return self.findings\n",
    "\n",
    "# ==============================\n",
    "# XSS Scanner\n",
    "# ==============================\n",
    "class XSSScanner:\n",
    "    def __init__(self, session, timeout=10):\n",
    "        self.session = session\n",
    "        self.timeout = timeout\n",
    "        self.findings = []\n",
    "\n",
    "    def test_url_params(self, url):\n",
    "        parsed = urlparse(url)\n",
    "        params = parse_qs(parsed.query)\n",
    "        if not params:\n",
    "            return\n",
    "        for param in params:\n",
    "            for payload in XSS_PAYLOADS:\n",
    "                test_params = params.copy()\n",
    "                test_params[param] = payload\n",
    "                new_query = urlencode(test_params, doseq=True)\n",
    "                new_url = urlunparse(parsed._replace(query=new_query))\n",
    "                try:\n",
    "                    resp = self.session.get(new_url, timeout=self.timeout)\n",
    "                    for pattern in REFLECT_PATTERNS:\n",
    "                        if pattern.search(resp.text):\n",
    "                            self.findings.append({\n",
    "                                \"type\": \"XSS-URL\",\n",
    "                                \"url\": new_url,\n",
    "                                \"parameter\": param,\n",
    "                                \"payload\": payload,\n",
    "                                \"evidence\": \"Payload reflected in response\"\n",
    "                            })\n",
    "                            print(f\"⚡ XSS detected in {new_url} param={param} payload={payload}\")\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "                time.sleep(0.2)\n",
    "\n",
    "    def test_forms(self, forms_by_url):\n",
    "        for page_url, forms in forms_by_url.items():\n",
    "            for form in forms:\n",
    "                action = form.get(\"action\") or page_url\n",
    "                method = form.get(\"method\", \"get\").lower()\n",
    "                base_data = {inp[\"name\"]: (inp.get(\"value\") or \"test\")\n",
    "                             for inp in form[\"inputs\"] if inp.get(\"name\")}\n",
    "                for field in base_data:\n",
    "                    for payload in XSS_PAYLOADS:\n",
    "                        test_data = base_data.copy()\n",
    "                        test_data[field] = payload\n",
    "                        try:\n",
    "                            if method == \"post\":\n",
    "                                resp = self.session.post(action, data=test_data,\n",
    "                                                         timeout=self.timeout)\n",
    "                            else:\n",
    "                                resp = self.session.get(action, params=test_data,\n",
    "                                                        timeout=self.timeout)\n",
    "                            for pattern in REFLECT_PATTERNS:\n",
    "                                if pattern.search(resp.text):\n",
    "                                    self.findings.append({\n",
    "                                        \"type\": \"XSS-FORM\",\n",
    "                                        \"url\": action,\n",
    "                                        \"field\": field,\n",
    "                                        \"parameter\": field,\n",
    "                                        \"payload\": payload,\n",
    "                                        \"evidence\": \"Payload reflected in response\"\n",
    "                                    })\n",
    "                                    print(f\"⚡ XSS detected in form {action} field={field} payload={payload}\")\n",
    "                                    break\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        time.sleep(0.2)\n",
    "\n",
    "    def run(self, pages, forms):\n",
    "        for url in pages.keys():\n",
    "            self.test_url_params(url)\n",
    "        self.test_forms(forms)\n",
    "        return self.findings\n",
    "\n",
    "# ==============================\n",
    "# Authentication & Access Control Testers\n",
    "# ==============================\n",
    "class AuthSessionTester:\n",
    "    DEFAULT_CREDENTIALS = [\n",
    "        (\"admin\", \"admin\"),\n",
    "        (\"admin\", \"password\"),\n",
    "        (\"root\", \"root\"),\n",
    "        (\"test\", \"test\")\n",
    "    ]\n",
    "\n",
    "    def __init__(self, base_url, session=None, timeout=10):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.findings = []\n",
    "\n",
    "    def test_weak_credentials(self, login_path=\"/login.php\"):\n",
    "        login_url = urljoin(self.base_url, login_path.lstrip(\"/\"))\n",
    "        print(f\"\\n🔎 Testing Weak Credentials at {login_url}\")\n",
    "        for user, pwd in self.DEFAULT_CREDENTIALS:\n",
    "            try:\n",
    "                r = self.session.get(login_url, timeout=self.timeout)\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                token = soup.find(\"input\", {\"name\": \"user_token\"})\n",
    "                token_val = token[\"value\"] if token else \"\"\n",
    "                data = {\n",
    "                    \"username\": user,\n",
    "                    \"password\": pwd,\n",
    "                    \"Login\": \"Login\",\n",
    "                    \"user_token\": token_val\n",
    "                }\n",
    "                resp = self.session.post(login_url, data=data, timeout=self.timeout)\n",
    "                if \"Logout\" in resp.text or \"Welcome\" in resp.text:\n",
    "                    evidence = f\"Login succeeded for {user}:{pwd}\"\n",
    "                    print(f\"🔥 Weak credentials found → {user}:{pwd}\")\n",
    "                    self.findings.append({\n",
    "                        \"type\": \"Weak-Credentials\",\n",
    "                        \"username\": user,\n",
    "                        \"password\": pwd,\n",
    "                        \"parameter\": user,\n",
    "                        \"payload\": pwd,\n",
    "                        \"evidence\": evidence\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"[-] {user}:{pwd} rejected\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] {e}\")\n",
    "            time.sleep(0.5)\n",
    "        return self.findings\n",
    "\n",
    "    def check_cookie_flags(self, login_path=\"/login.php\"):\n",
    "        login_url = urljoin(self.base_url, login_path.lstrip(\"/\"))\n",
    "        print(\"\\n🔎 Checking Cookie Flags\")\n",
    "        try:\n",
    "            resp = self.session.get(login_url, timeout=self.timeout)\n",
    "            set_cookie = resp.headers.get(\"set-cookie\", \"\")\n",
    "            issues = []\n",
    "            if \"httponly\" not in set_cookie.lower():\n",
    "                issues.append(\"Missing HttpOnly\")\n",
    "            if \"secure\" not in set_cookie.lower():\n",
    "                issues.append(\"Missing Secure\")\n",
    "            if \"samesite\" not in set_cookie.lower():\n",
    "                issues.append(\"Missing SameSite\")\n",
    "            if issues:\n",
    "                evidence = \", \".join(issues)\n",
    "                print(\"⚠️ Cookie flag issues:\", evidence)\n",
    "                self.findings.append({\n",
    "                    \"type\": \"Cookie-Issues\",\n",
    "                    \"issues\": issues,\n",
    "                    \"evidence\": evidence,\n",
    "                    \"parameter\": \"-\"\n",
    "                })\n",
    "            else:\n",
    "                print(\"✅ Cookie flags appear secure\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {e}\")\n",
    "        return self.findings\n",
    "\n",
    "class AccessControlTester:\n",
    "    def __init__(self, base_url, session=None, timeout=10):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.findings = []\n",
    "\n",
    "    def test_idor(self, path=\"/vulnerabilities/idor/\", param=\"id\", start=1, stop=3):\n",
    "        url = urljoin(self.base_url, path.lstrip(\"/\"))\n",
    "        print(f\"\\n🔎 Testing IDOR at {url} (param={param})\")\n",
    "        for uid in range(start, stop + 1):\n",
    "            try:\n",
    "                resp = self.session.get(url, params={param: uid}, timeout=self.timeout)\n",
    "                body = (resp.text or \"\").lower()\n",
    "                if \"unauthorized\" not in body and \"forbidden\" not in body:\n",
    "                    if \"username\" in body or \"email\" in body or \"account\" in body:\n",
    "                        evidence = f\"Accessed user data for {param}={uid}\"\n",
    "                        print(f\"🔥 Possible IDOR → accessed data for {param}={uid}\")\n",
    "                        self.findings.append({\n",
    "                            \"type\": \"IDOR\",\n",
    "                            \"url\": url,\n",
    "                            \"param\": param,\n",
    "                            \"parameter\": param,\n",
    "                            \"value\": uid,\n",
    "                            \"evidence\": evidence\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"[?] {param}={uid} returned content (needs review)\")\n",
    "                else:\n",
    "                    print(f\"[-] {param}={uid} blocked\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] {e}\")\n",
    "        return self.findings\n",
    "\n",
    "    def test_role_bypass(self, protected_paths=None):\n",
    "        if protected_paths is None:\n",
    "            protected_paths = [\"/admin/\", \"/config.php\", \"/vulnerabilities/\"]\n",
    "        print(\"\\n🔎 Testing Access Control (Role Bypass)\")\n",
    "        for path in protected_paths:\n",
    "            url = urljoin(self.base_url, path.lstrip(\"/\"))\n",
    "            try:\n",
    "                resp = requests.get(url, timeout=self.timeout)  # new session (unauth)\n",
    "                if resp.status_code == 200 and \"login\" not in resp.text.lower():\n",
    "                    evidence = f\"Accessible without auth (HTTP {resp.status_code})\"\n",
    "                    print(f\"🔥 Access Control issue → {url} accessible without login\")\n",
    "                    self.findings.append({\n",
    "                        \"type\": \"Access-Control\",\n",
    "                        \"url\": url,\n",
    "                        \"status\": resp.status_code,\n",
    "                        \"parameter\": \"-\",\n",
    "                        \"evidence\": evidence\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"[-] {url} seems protected\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] {e}\")\n",
    "        return self.findings\n",
    "\n",
    "# ==============================\n",
    "# Main Runner\n",
    "# ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"http://localhost:8080\"  # Change to your DVWA or test target\n",
    "\n",
    "    shared_session = requests.Session()\n",
    "\n",
    "    # Step 1: Crawl\n",
    "    crawler = DVWACrawler(base_url, session=shared_session, username=\"admin\", password=\"password\",\n",
    "                          max_pages=15, delay=1)\n",
    "    crawl_results = crawler.crawl()\n",
    "\n",
    "    # Step 2: SQL Injection Scan\n",
    "    sqli_scanner = SQLiScanner(crawl_results[\"session\"])\n",
    "    sqli_findings = sqli_scanner.run(crawl_results[\"pages\"], crawl_results[\"forms\"])\n",
    "\n",
    "    # Step 3: XSS Scan\n",
    "    xss_scanner = XSSScanner(crawl_results[\"session\"])\n",
    "    xss_findings = xss_scanner.run(crawl_results[\"pages\"], crawl_results[\"forms\"])\n",
    "\n",
    "    # Step 4: Authentication & Access Control\n",
    "    auth_tester = AuthSessionTester(base_url, session=crawl_results[\"session\"])\n",
    "    auth_findings = auth_tester.test_weak_credentials()\n",
    "    cookie_findings = auth_tester.check_cookie_flags()\n",
    "\n",
    "    access_tester = AccessControlTester(base_url, session=crawl_results[\"session\"])\n",
    "    idor_findings = access_tester.test_idor(path=\"/vulnerabilities/idor/\", param=\"id\", start=1, stop=5)\n",
    "    role_bypass_findings = access_tester.test_role_bypass()\n",
    "\n",
    "    # Aggregate findings\n",
    "    all_findings = sqli_findings + xss_findings + auth_tester.findings + access_tester.findings\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"\\n=== Vulnerability Findings ===\")\n",
    "    if all_findings:\n",
    "        for f in all_findings:\n",
    "            print(f\"[{f.get('type')}]\")\n",
    "            if 'url' in f:\n",
    "                print(f\"   URL: {f.get('url')}\")\n",
    "            if 'parameter' in f:\n",
    "                print(f\"   Parameter: {f.get('parameter')}\")\n",
    "            if 'param' in f:\n",
    "                print(f\"   Param (alias): {f.get('param')}\")\n",
    "            if 'field' in f:\n",
    "                print(f\"   Field: {f.get('field')}\")\n",
    "            if 'username' in f:\n",
    "                print(f\"   Username: {f.get('username')}\")\n",
    "            if 'password' in f:\n",
    "                print(f\"   Password: {f.get('password')}\")\n",
    "            if 'value' in f:\n",
    "                print(f\"   Value: {f.get('value')}\")\n",
    "            if 'error' in f:\n",
    "                print(f\"   Error: {f.get('error')}\")\n",
    "            if 'issues' in f:\n",
    "                print(f\"   Issues: {f.get('issues')}\")\n",
    "            if 'evidence' in f:\n",
    "                print(f\"   Evidence: {f.get('evidence')}\")\n",
    "            print(\"-\" * 50)\n",
    "    else:\n",
    "        print(\"No SQLi, XSS, authentication, or access control vulnerabilities detected.\")\n",
    "\n",
    "    # HTML Report\n",
    "    try:\n",
    "        reporter = Reporter(base_url, all_findings, out_dir='reports')\n",
    "        report_path = reporter.render_html()\n",
    "        print(f\"\\n📄 HTML report generated: {report_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to generate HTML report: {e}\")\n",
    "\n",
    "    print(\"\\n=== Mitigation Tips ===\")\n",
    "    print(\"SQLi Fixes: Use parameterized queries (PreparedStatements), ORM, input validation.\")\n",
    "    print(\"XSS Fixes: Validate input, encode output, apply Content Security Policy (CSP).\")\n",
    "    print(\"Auth/Access Control: Enforce strong passwords, rate limit login attempts, set cookie flags (HttpOnly, Secure, SameSite), and apply proper authorization checks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f848dc-22cb-42d1-8213-c265a8e024d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
